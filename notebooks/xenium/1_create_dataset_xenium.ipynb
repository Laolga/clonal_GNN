{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle   \n",
    "from collections import Counter\n",
    "import os\n",
    "os.chdir(\"/home/o313a/clonal_GNN/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv(\"data/interim/edges_xenium_new.csv\",\n",
    "dtype = {\"node1\":str, \"node2\":str})\n",
    "overcl = pd.read_csv(\"data/interim/clones_over.csv\")\n",
    "overcl.columns = [\"node1\",\"clone\"]\n",
    "overcl.node1 = [x[:-2] for x in overcl.node1]\n",
    "cell_type = pd.read_excel(\"data/raw/Requested_Cell_Barcode_Type_Matrices.xlsx\", sheet_name=\"scFFPE-Seq\")\n",
    "cell_type.columns = [\"node1\",\"cell_type\"]\n",
    "overcl = cell_type.merge(overcl, on = \"node1\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(edges.node2).difference(set(edges.node1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edges = edges[edges[\"type\"]!= \"sc2sc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_counts(counter, threshold, label):\n",
    "    for key, value in counter.items():\n",
    "        assert value > threshold, f\"{label} {key} has less than {threshold + 1} items\"\n",
    "        \n",
    "\n",
    "def filter_and_encode(df, node_encoder, all_nodes,use_index=False):\n",
    "    if use_index:\n",
    "        df = df[df.index.isin(all_nodes)]\n",
    "    else:\n",
    "        df = df[df.node1.isin(all_nodes) & df.node2.isin(all_nodes)]\n",
    "\n",
    "\n",
    "    if use_index:\n",
    "        df = df.rename(index=node_encoder)\n",
    "    else:\n",
    "        df.node1 = df.node1.map(node_encoder)\n",
    "        df.node2 = df.node2.map(node_encoder)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_data(edges, overcl, spatial_edges):\n",
    "    # Filter and fill missing values\n",
    "    overcl = overcl.merge(edges[edges[\"type\"] != spatial_edges], on=\"node1\", how=\"left\")\n",
    "    overcl = overcl[[\"node1\", \"clone\", \"cell_type\"]].drop_duplicates()    \n",
    "    # Validation\n",
    "    validate_counts(Counter(overcl.cell_type), 20, \"Cell type\")\n",
    "    validate_counts(Counter(overcl.clone), 20, \"Clone\")\n",
    "    \n",
    "    edges = edges.merge(overcl[[\"clone\", \"node1\", \"cell_type\"]], on=\"node1\", how=\"left\")\n",
    "    drop_nodes_clone = edges[(edges[\"type\"]!= \"xen2grid\")&(edges.clone.isna())].node1\n",
    "    drop_nodes_ct = edges[(edges[\"type\"]!= \"xen2grid\")&(edges.cell_type.isna())].node1\n",
    "    to_drop = list(set(drop_nodes_clone).union(set(drop_nodes_ct)))\n",
    "    edges = edges[~edges.node1.isin(to_drop)]\n",
    "    edges = edges[~edges.node2.isin(to_drop)]\n",
    "    return edges, overcl\n",
    "\n",
    "\n",
    "def read_and_merge_embeddings(paths, edges):\n",
    "    all_nodes_graph = set(edges.node1).union(set(edges.node2))\n",
    "    emb_vis = pd.read_csv(paths[\"spatial\"], index_col=0)\n",
    "    emb_vis.index = emb_vis.index.map(str)\n",
    "    emb_rna = pd.read_csv(paths[\"rna\"], index_col=0)\n",
    "    emb_rna.index = emb_rna.index.map(str)\n",
    "\n",
    "    all_nodes_emb = set(emb_vis.index).union(set(emb_rna.index))\n",
    "    all_nodes = list(all_nodes_graph.intersection(all_nodes_emb))\n",
    "    node_encoder = {all_nodes[i]:i for i in range(len(all_nodes))}\n",
    "    emb_vis = filter_and_encode(emb_vis, node_encoder, all_nodes, use_index=True)\n",
    "    emb_rna = filter_and_encode(emb_rna, node_encoder, all_nodes, use_index=True)\n",
    "    edges = filter_and_encode(edges, node_encoder, all_nodes)\n",
    "\n",
    "    \n",
    "    return emb_vis, emb_rna, edges, node_encoder\n",
    "\n",
    "\n",
    "def create_data_object(edges, emb_vis, emb_rna,node_encoder):\n",
    "    # Convert to tensors\n",
    "    edge_index = torch.tensor([edges.node1.values, edges.node2.values], dtype=torch.long)\n",
    "    edge_weight = torch.tensor(edges.weight.values, dtype=torch.float)\n",
    "    features = pd.concat([emb_vis, emb_rna]).sort_index()\n",
    "    x = torch.tensor(features.values, dtype=torch.float)\n",
    "    \n",
    "    # Encode attributes\n",
    "    edges.clone = edges.clone.fillna(\"missing\")\n",
    "    edges.cell_type = edges.cell_type.fillna(\"missing\")\n",
    "\n",
    "    nodes_attr = edges[[\"node1\", \"cell_type\", \"clone\"]].drop_duplicates().sort_values(by=\"node1\")\n",
    "    clone_dict = create_encoding_dict(nodes_attr, \"clone\", extras=[\"diploid\", \"missing\"])\n",
    "    type_dict = create_encoding_dict(nodes_attr, \"cell_type\", extras=[\"missing\"])\n",
    "    \n",
    "    nodes_attr[\"clone\"] = nodes_attr[\"clone\"].map(clone_dict)\n",
    "    nodes_attr[\"cell_type\"] = nodes_attr[\"cell_type\"].map(type_dict)\n",
    "    nodes_attr = nodes_attr.set_index(\"node1\")\n",
    "    features = features.join(nodes_attr)\n",
    "    \n",
    "    y_clone = torch.tensor(features.clone.values, dtype=torch.long)\n",
    "    y_type = torch.tensor(features.cell_type.values, dtype=torch.long)\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, y_clone=y_clone, y_type=y_type, edge_type=edges.type.values, edge_attr=edge_weight)\n",
    "    assert data.validate(raise_on_error=True), \"Data not valid\"\n",
    "    assert data.x.shape[0] == data.y_clone.shape[0] == data.y_type.shape[0], \"Data not valid\"\n",
    "    \n",
    "    return data, {\"nodes\": node_encoder, \"clones\": clone_dict, \"types\": type_dict}\n",
    "\n",
    "\n",
    "def create_encoding_dict(df, column, extras=[]):\n",
    "    items = list(df[column].unique())\n",
    "    for extra in extras:\n",
    "        items.remove(extra)\n",
    "    if \"diploid\" in extras:\n",
    "        dt = {x:int(x) for x in items}\n",
    "        dt[\"missing\"] = -1\n",
    "        dt[\"diploid\"] = len(dt)-1\n",
    "    else:\n",
    "        dt = {item: idx for idx, item in enumerate(items)}\n",
    "        dt[\"missing\"] = -1\n",
    "\n",
    "\n",
    "    return dt\n",
    "\n",
    "\n",
    "embedding_paths = {\n",
    "    \"spatial\": \"data/interim/embedding_spatial_xenium.csv\",\n",
    "    \"rna\": \"data/interim/embedding_rna_xenium.csv\"\n",
    "}\n",
    "edges, overcl = preprocess_data(edges, overcl,\"sc2xen\")\n",
    "\n",
    "emb_vis, emb_rna, edges, node_encoder = read_and_merge_embeddings(embedding_paths, edges)\n",
    "\n",
    "data, encoding_dict = create_data_object(edges, emb_vis, emb_rna, node_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data, \"data/processed/data_xen.pt\")\n",
    "with open('data/processed/full_encoding_xen.pkl', 'wb') as fp:\n",
    "    pickle.dump(encoding_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_attr = data.edge_attr.reshape((-1,1))\n",
    "hold_out_indices = np.where(data.y_clone == -1)[0]\n",
    "hold_out = torch.tensor(hold_out_indices, dtype=torch.long)\n",
    "hold_in_indices = np.arange(data.x.shape[0])\n",
    "hold_in = [index for index in hold_in_indices if index not in hold_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_clone[hold_in].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[10] * 3,\n",
    "    batch_size=128,input_nodes = hold_in\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data.edge_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dat in loader:\n",
    "    assert -1 not in dat.y_clone.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 26])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.y_clone.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
